[Clang]
library_file = /usr/local/Cellar/llvm/7.0.1/lib/libclang.dylib


[Model]
; used to select the model below to use
; must be one of 'random_forest', 'logit', 'svm', or 'naive_bayes'
model_name = random_forest
train_size = 2/3
number_of_authors = -1


;; MODELS ;;
[random_forest]
n_estimators = 300
oob_score = True
max_features = "sqrt"

[logit]
; Logistic Regression
penalty = l2
solver = saga
multi_class = multinomial
; NOTE: Set a random_state value when solver == ‘sag’ or ‘liblinear’.
random_state = None

[svm]
; Linear SVM
penalty = l2
loss = squared_hinge
; TODO: From docs: "Prefer dual=False when n_samples > n_features." Account for this later
dual = True
random_state = None
tol = 1e-4

[naive_bayes]
; Multinomial Naive Bayes
alpha = 1.0


[Feature Selection]
reduction_factor = 0.5
num_best_features = 50
n_estimators = 300
oob_score = True
max_features = sqrt

[Cross Validation]
n_splits = 3
train_ratio = 0.5
test_ratio = 0.2
train_min = 1000
test_min = 200

[Sanity Check]
fit_size = 1/2
num_authors = -1