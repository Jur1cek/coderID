# Put Python keywords/functions in quotations.

[Clang]
library_file = /usr/local/Cellar/llvm/7.0.1/lib/libclang.dylib

[Features]
# flags for the types of features to include/exclude
# TODO: implement these flags
whitespace = True
comments = True
nesting_depth = True
literals_as_tokens = True
token_level = True
char_level = True
unigram_level = True
token_keywords = ["do", "else", "for", "if", "switch", "while", "new", "this", "auto", "enum", "operator", "throw", "bool", "explicit", "private", "true", "export", "protected", "case", "extern", "public", "typedef", "register", "typeid", "union", "const", "friend", "short", "goto", "using", "continue", "sizeof", "virtual", "default", "inline", "static", "delete", "volatile", "struct", "mutable", "template"]
# include flag for tf-only features?

[Feature Selection]
reduction_factor = 0.1
num_best_features = 50
n_estimators = 500
oob_score = True
max_features = sqrt
n_splits = 3
max_samples = 1000

[Pruning]
max_authors = 10000
min_functions = 50
max_functions = 10000

[CodeJam]
max_authors = 50
min_files = 5



[Model]
# Classifier details
model_name = random_forest
train_size = 2/3
number_of_authors = -1

# Model parameters by classifier
[random_forest]
n_estimators = 300
oob_score = True
max_features = "sqrt"

[logit]
penalty = l2
solver = saga
multi_class = multinomial
random_state = None

[svm]
penalty = l2
loss = squared_hinge
dual = True
random_state = None
tol = 1e-4


[Cross Validation]
n_splits = 2
train_ratio = 0.2
test_ratio = 0.2
train_min = 1000
test_min = 200

[Sanity Check]
fit_size = 1/2
num_authors = -1

