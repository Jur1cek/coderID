[Clang]
library_file = /usr/local/Cellar/llvm/7.0.1/lib/libclang.dylib

[Model]
; used to select the model below to use
; must be one of 'random_forest', 'logit', 'svm', or 'naive_bayes'
model_name = random_forest
fit_size = 2/3
number_of_authors = -1

    [Random Forest]
    n_estimators = 300
    oob_score = True
    max_features = sqrt

    [Logistic Regression]
    penalty = l2
    solver = saga
    multi_class = multinomial
    ; NOTE: Set a random_state value when solver == ‘sag’ or ‘liblinear’.
    random_state = None

    [Linear SVM]
    penalty = l2
    loss = squared_hinge
    ; TODO: From docs: "Prefer dual=False when n_samples > n_features." Account for this later
    dual = True
    random_state = None
    tol = 1e-4

    [Naive Bayes]
    alpha = 1.0

[Feature Selection]
mi_threshold = 0.1
num_best_features = 50

[Cross Validation]
n_splits = 5
train_size = 0.2
test_size = 0.2

[Sanity Check]
fit_size = 1/2
num_authors = -1